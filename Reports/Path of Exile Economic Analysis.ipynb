{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from scipy import stats\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "sns.set_style(\"white\")\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_header_clean(df):\n",
    "    column_map = {\n",
    "    \"index\" : \"League\",\n",
    "    \"League\": \"Date\",\n",
    "    \"Date\": \"Id\",\n",
    "    \"Id\" : \"Type\"\n",
    "    }\n",
    "    df_indexreset = df.reset_index()\n",
    "    df_renamed = df_indexreset.rename(columns = column_map)\n",
    "    return df_renamed\n",
    "\n",
    "def item_info_fix(df):\n",
    "    cols_to_drop = [\"Links\", \"Variant\"]\n",
    "    df_cols_dropped = df.drop(cols_to_drop, axis = 1)\n",
    "    df_cols_dropped.BaseType = df_cols_dropped.BaseType.fillna(df_cols_dropped.Type)\n",
    "    df_fixed = df_cols_dropped\n",
    "    return df_fixed\n",
    "\n",
    "def item_top_40_filter(df):\n",
    "    median_series = df.groupby(\"Name\")[\"Value\"].agg(\"median\")\n",
    "    sorted_series = median_series.sort_values(ascending = False)\n",
    "    top_40_list = list(sorted_series[:40].index)\n",
    "    df_top_40 = df.loc[df[\"Name\"].isin(top_40_list)]\n",
    "    return df_top_40\n",
    "\n",
    "def add_relative_date(df):\n",
    "    df_copy = df\n",
    "    df_copy[\"Date\"] = df_copy[\"Date\"].astype('datetime64[D]')\n",
    "    startdate = df_copy[\"Date\"].min()\n",
    "    df_copy[\"RelativeDate\"] = (df_copy[\"Date\"] - startdate)\n",
    "    df_edited = df_copy.drop(\"Date\", axis = 1)\n",
    "    df_edited[\"RelativeDate\"] = pd.to_timedelta(df_edited[\"RelativeDate\"], unit = \"D\")\n",
    "    df_edited[\"RelativeDateInt\"] = df_edited[\"RelativeDate\"] / np.timedelta64(1, 'D')\n",
    "    return df_edited\n",
    "\n",
    "def league_lifespan(row):\n",
    "    early_league = dt.timedelta(days = 14)\n",
    "    mid_league = dt.timedelta(days = 60)\n",
    "    if row[\"RelativeDate\"] <= early_league:\n",
    "        return \"Early\"\n",
    "    elif row[\"RelativeDate\"] <= mid_league:\n",
    "        return \"Mid\"\n",
    "    return \"End\"\n",
    "\n",
    "def item_file_clean(df):\n",
    "    df1 = item_header_clean(df)\n",
    "    df2 = item_info_fix(df1)\n",
    "    df3 = item_top_40_filter(df2)\n",
    "    df4 = add_relative_date(df3)\n",
    "    df4[\"League Lifespan\"] = df4.apply(league_lifespan, axis = 1)\n",
    "    return df4\n",
    "\n",
    "def currency_info_fix(df):\n",
    "    currency_to_drop = [\"Portal Scroll\", \"Scroll of Wisdom\", \"Armourer's Scrap\", \"Perandus Coin\", \"Orb of Transmutation\", \"Blacksmith's Whetstone\", \"Orb of Augmentation\", \"Orb of Alteration\", \"Splinter of Tul\", \"Chromatic Orb\", \"Splinter of Esh\", \"Splinter of Xoph\", \"Orb of Chance\", \"Glassblower's Bauble\", \"Splinter of Uul-Netol\", \"Silver Coin\"]\n",
    "    df_currency_fixed = df.loc[~(df[\"Get\"].isin(currency_to_drop) | df[\"Pay\"].isin(currency_to_drop))]\n",
    "    return df_currency_fixed\n",
    "\n",
    "def currency_file_clean(df):\n",
    "    df1 = currency_info_fix(df)\n",
    "    df2 = add_relative_date(df1)\n",
    "    df2[\"League Lifespan\"] = df2.apply(league_lifespan, axis = 1)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Import and Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e16e8f546565>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdf_edited\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_file_clean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mitem_df_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_edited\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mitem_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_df_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mitem_df_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mitem_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    223\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                        copy=copy, sort=sort)\n\u001b[0m\u001b[0;32m    226\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No objects to concatenate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# Import/Concatenate item files\n",
    "item_df_list = []\n",
    "for filename in glob.glob(\"*_items.csv\"):\n",
    "    df = pd.read_csv(filename, delimiter = \";\", low_memory = False)\n",
    "    df_edited = item_file_clean(df)\n",
    "    item_df_list.append(df_edited)\n",
    "item_df = pd.concat(item_df_list, axis = 0)\n",
    "del item_df_list\n",
    "item_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import/Concatenate currency files\n",
    "currency_df_list = []\n",
    "for filename in glob.glob(\"*_currency.csv\"):\n",
    "    df = pd.read_csv(filename, delimiter = \";\", low_memory = False)\n",
    "    df_edited = currency_file_clean(df)\n",
    "    currency_df_list.append(df_edited)\n",
    "currency_df = pd.concat(currency_df_list, axis = 0)\n",
    "del currency_df_list\n",
    "currency_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paring down item table to only include items common across all leagues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def common_items(df):\n",
    "    unique_items = []\n",
    "    for league in df.League.unique():\n",
    "        league_df = df[df.League == league]\n",
    "        unique_items.append(league_df.Name.unique().tolist())\n",
    "    return list(set(unique_items[0]).intersection(*unique_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_items = common_items(item_df)\n",
    "\n",
    "#Remove specific items that don't make sense to track due to variations or lack of accessibility\n",
    "items_to_remove = [\"Eyes of the Greatwolf\", \"Demigod's Dominance\"]\n",
    "for item in items_to_remove:\n",
    "    list_of_items.remove(item)\n",
    "\n",
    "item_df_pared = item_df.loc[item_df[\"Name\"].isin(list_of_items)]\n",
    "\n",
    "#Set up specific item lists that group items with possible dependencies on each other\n",
    "hh_items = [\"The Fiend\", \"The Doctor\", \"Headhunter\"]\n",
    "chayula_items = [\"United in Dream\", \"The Blue Nightmare\", \"The Green Nightmare\", \"The Red Nightmare\"]\n",
    "misc_items = [\"Starforge\", \"The Retch\", \"Atziri's Disfavour\", \"Emperor's Mastery\", \"Skyforth\", \"Atziri's Acuity\"]\n",
    "misc_pd = [\"House of Mirrors\", \"Trash to Treasure\", \"Fated Connections\"]\n",
    "list_of_groups = [hh_items, chayula_items, misc_items, misc_pd]\n",
    "item_group_names = [\"Headhunter Related Items\", \"Chayula Related Items\", \"Miscellaneous Items\", \"Miscellaneous Prophecies/Divination Cards\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pare down both item and currency table to only include the last 90 days and not the first day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df_pared = item_df_pared[(item_df_pared[\"RelativeDateInt\"] <= 90) & (item_df_pared[\"RelativeDateInt\"] > 1)]\n",
    "currency_df_pared = currency_df[(currency_df[\"RelativeDateInt\"] <= 90) & (currency_df[\"RelativeDateInt\"] > 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (Visualization and Inferential Statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization - Item Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By League"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "league_indexed_items = item_df_pared.set_index(\"League\")\n",
    "league_indexed_items = league_indexed_items.sort_index()\n",
    "league_name_list = list(league_indexed_items.index.unique())\n",
    "league_name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization - Currency Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By League"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferential Statistics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
